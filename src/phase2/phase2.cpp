#include <mpi.h>
#include <iostream>
#include <vector>
#include <unordered_map>
#include <cmath>
#include <numeric>
#include <algorithm>
#include <iomanip>
#include <chrono>
#include <cuda_runtime.h>
#include <unistd.h>
#include <cstring>
#include <map>
#include <omp.h>

#include "graph_types.h"
#include "phase2/phase2.h"
#include "phase2/gpu_lp_boundary.h"

// === ê³µí†µ í•¨ìˆ˜ë“¤ ===

// Ghost ë…¸ë“œ ë¼ë²¨ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ëŠ” ì¸ë¼ì¸ í•¨ìˆ˜
inline int getNodeLabel(int node_id, const Graph &g, const std::vector<int> &labels, 
                       const GhostNodes &ghost_nodes) {
    if (node_id < g.num_vertices) {
        return labels[node_id];
    } else {
        int ghost_idx = node_id - g.num_vertices;
        return (ghost_idx >= 0 && ghost_idx < (int)ghost_nodes.ghost_labels.size()) 
               ? ghost_nodes.ghost_labels[ghost_idx] : -1;
    }
}

// íŒŒí‹°ì…˜ë³„ í†µê³„ ê³„ì‚° (ìµœì í™”ëœ ë²„ì „ - í•œ ë²ˆì˜ MPI í˜¸ì¶œë¡œ í†µí•©)
static PartitionStats computePartitionStats(const Graph &g, const std::vector<int> &labels, 
                                           const GhostNodes &ghost_nodes, int num_partitions) {
    PartitionStats stats;
    stats.local_vertex_counts.resize(num_partitions, 0);
    stats.local_edge_counts.resize(num_partitions, 0);
    stats.global_vertex_counts.resize(num_partitions, 0);
    stats.global_edge_counts.resize(num_partitions, 0);

    // ê° íŒŒí‹°ì…˜ì˜ ë…¸ë“œ ìˆ˜ ê³„ì‚° (owned ë…¸ë“œë§Œ) - OpenMP ë³‘ë ¬í™”
    #pragma omp parallel
    {
        std::vector<int> thread_vertex_counts(num_partitions, 0);
        
        #pragma omp for nowait
        for (int u = 0; u < g.num_vertices; u++) {
            int label = labels[u];
            if (label >= 0 && label < num_partitions) {
                thread_vertex_counts[label]++;
            }
        }
        
        #pragma omp critical
        {
            for (int i = 0; i < num_partitions; i++) {
                stats.local_vertex_counts[i] += thread_vertex_counts[i];
            }
        }
    }
    
    // ê° íŒŒí‹°ì…˜ì˜ ê°„ì„  ìˆ˜ ê³„ì‚° (íŒŒí‹°ì…˜ ë‚´ë¶€ ê°„ì„ ë§Œ) - OpenMP ë³‘ë ¬í™”
    #pragma omp parallel
    {
        std::vector<int> thread_edge_counts(num_partitions, 0);
        
        #pragma omp for nowait
        for (int u = 0; u < g.num_vertices; u++) {
            int label_u = labels[u];
            if (label_u < 0 || label_u >= num_partitions) continue;
            
            for (int e = g.row_ptr[u]; e < g.row_ptr[u + 1]; e++) {
                int v = g.col_indices[e];
                int label_v = getNodeLabel(v, g, labels, ghost_nodes);
                
                if (label_v >= 0 && label_v < num_partitions && label_u == label_v) {
                    thread_edge_counts[label_u]++;
                }
            }
        }
        
        #pragma omp critical
        {
            for (int i = 0; i < num_partitions; i++) {
                stats.local_edge_counts[i] += thread_edge_counts[i];
            }
        }
    }

    // ğŸ’¡ ìµœì í™”: ë‹¨ì¼ MPI í˜¸ì¶œë¡œ í†µí•© (vertex + edge counts ë™ì‹œ ì „ì†¡)
    std::vector<int> send_buffer(2 * num_partitions);
    std::vector<int> recv_buffer(2 * num_partitions);
    
    // ë²„í¼ íŒ¨í‚¹: [vertex_counts..., edge_counts...]
    std::copy(stats.local_vertex_counts.begin(), stats.local_vertex_counts.end(), send_buffer.begin());
    std::copy(stats.local_edge_counts.begin(), stats.local_edge_counts.end(), send_buffer.begin() + num_partitions);
    
    // ë‹¨ì¼ Allreduceë¡œ ëª¨ë“  ì¹´ìš´íŠ¸ ì§‘ê³„
    MPI_Allreduce(send_buffer.data(), recv_buffer.data(), 2 * num_partitions, MPI_INT, MPI_SUM, MPI_COMM_WORLD);
    
    // ê²°ê³¼ ì–¸íŒ¨í‚¹
    std::copy(recv_buffer.begin(), recv_buffer.begin() + num_partitions, stats.global_vertex_counts.begin());
    std::copy(recv_buffer.begin() + num_partitions, recv_buffer.end(), stats.global_edge_counts.begin());

    // ì „ì²´ ê·¸ë˜í”„ í¬ê¸° ê³„ì‚°
    stats.total_vertices = std::accumulate(stats.global_vertex_counts.begin(), stats.global_vertex_counts.end(), 0);
    stats.total_edges = std::accumulate(stats.global_edge_counts.begin(), stats.global_edge_counts.end(), 0);

    // ê· ë“± ë¶„ë°° ê¸°ì¤€ê°’
    stats.expected_vertices = static_cast<double>(stats.total_vertices) / num_partitions;
    stats.expected_edges = (stats.total_edges > 0) ? static_cast<double>(stats.total_edges) / num_partitions : 1.0;

    return stats;
}

// MPI Delta í†µì‹  í—¬í¼ í•¨ìˆ˜
static std::vector<Delta> allgatherDeltas(const std::vector<Delta> &local_deltas, int mpi_size) {
    int send_count = local_deltas.size();
    std::vector<int> recv_counts(mpi_size);
    
    MPI_Allgather(&send_count, 1, MPI_INT, recv_counts.data(), 1, MPI_INT, MPI_COMM_WORLD);

    std::vector<int> displs(mpi_size);
    displs[0] = 0;
    for (int i = 1; i < mpi_size; i++)
        displs[i] = displs[i - 1] + recv_counts[i - 1];
    int total_recv = displs[mpi_size - 1] + recv_counts[mpi_size - 1];

    std::vector<Delta> recv_deltas(total_recv);

    // Deltaìš© MPI íƒ€ì… ì •ì˜
    MPI_Datatype MPI_DELTA;
    MPI_Type_contiguous(2, MPI_INT, &MPI_DELTA);
    MPI_Type_commit(&MPI_DELTA);

    MPI_Allgatherv(local_deltas.data(), send_count, MPI_DELTA,
                   recv_deltas.data(), recv_counts.data(), displs.data(),
                   MPI_DELTA, MPI_COMM_WORLD);

    MPI_Type_free(&MPI_DELTA);
    
    return recv_deltas;
}

// === Penalty ê³„ì‚° ë°©ì‹ ì„ íƒ (ì‹¤í—˜ìš©) ===
// #define USE_MASTER_WORKER_PENALTY  // ì´ ì¤„ì„ ì£¼ì„ í•´ì œí•˜ë©´ Master-Worker ë°©ì‹ ì‚¬ìš©

#ifdef USE_MASTER_WORKER_PENALTY
// Master-Worker ë°©ì‹: Rank 0ë§Œ ê³„ì‚°, ê²°ê³¼ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸
std::vector<double> calculatePenalties(
    const PartitionStats &stats,
    int num_partitions,
    int mpi_rank = 0)
{
    std::vector<double> penalties(num_partitions);
    
    // Rank 0ë§Œ penalty ê³„ì‚° ìˆ˜í–‰
    if (mpi_rank == 0) {
        // RV, RE ë¹„ìœ¨ ê³„ì‚°
        std::vector<double> RV(num_partitions), RE(num_partitions);
        for (int i = 0; i < num_partitions; i++) {
            RV[i] = (stats.expected_vertices > 0) ? static_cast<double>(stats.global_vertex_counts[i]) / stats.expected_vertices : 1.0;
            RE[i] = (stats.expected_edges > 0) ? static_cast<double>(stats.global_edge_counts[i]) / stats.expected_edges : 1.0;
        }
        
        // ë””ë²„ê¹… ì¶œë ¥ (Rank 0ë§Œ)
        printf("\n=== Label Statistics (Master-Worker ë°©ì‹) ===\n");
        printf("Total: %d vertices, %d edges\n", stats.total_vertices, stats.total_edges);
        printf("Expected per label: %.1f vertices, %.1f edges\n", stats.expected_vertices, stats.expected_edges);
        
        for (int i = 0; i < num_partitions; i++) {
            printf("Label %d: %d vertices (%.3f), %d edges (%.3f)\n", 
                   i, stats.global_vertex_counts[i], RV[i], 
                   stats.global_edge_counts[i], RE[i]);
        }
        printf("========================\n\n");

        // Penalty ì§ì ‘ ê³„ì‚°
        double rv_mean = 0.0, re_mean = 0.0;
        for (int i = 0; i < num_partitions; i++) {
            rv_mean += RV[i];
            re_mean += RE[i];
        }
        rv_mean /= num_partitions;
        re_mean /= num_partitions;

        double rv_var = 0.0, re_var = 0.0;
        for (int i = 0; i < num_partitions; i++) {
            rv_var += (RV[i] - rv_mean) * (RV[i] - rv_mean);
            re_var += (RE[i] - re_mean) * (RE[i] - re_mean);
        }
        rv_var /= num_partitions;
        re_var /= num_partitions;

        double total_var = rv_var + re_var;
        double imb_rv = (total_var > 0) ? rv_var / total_var : 0.0;
        double imb_re = (total_var > 0) ? re_var / total_var : 0.0;

        // Penalty ë°°ì—´ ì§ì ‘ ìƒì„±
        for (int i = 0; i < num_partitions; i++) {
            double G_RV = (1.0 - RV[i]) / num_partitions;
            double G_RE = (1.0 - RE[i]) / num_partitions;
            penalties[i] = imb_rv * G_RV + imb_re * G_RE;
        }
    }
    
    // ê²°ê³¼ë¥¼ ëª¨ë“  í”„ë¡œì„¸ì„œì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
    MPI_Bcast(penalties.data(), num_partitions, MPI_DOUBLE, 0, MPI_COMM_WORLD);
    
    return penalties;
}

#else
// ê¸°ì¡´ ë°©ì‹: ëª¨ë“  í”„ë¡œì„¸ì„œê°€ ë™ì¼í•œ ê³„ì‚° ìˆ˜í–‰
std::vector<double> calculatePenalties(
    const PartitionStats &stats,
    int num_partitions,
    int mpi_rank = 0)
{
    // RV, RE ë¹„ìœ¨ ê³„ì‚°
    std::vector<double> RV(num_partitions), RE(num_partitions);
    for (int i = 0; i < num_partitions; i++) {
        RV[i] = (stats.expected_vertices > 0) ? static_cast<double>(stats.global_vertex_counts[i]) / stats.expected_vertices : 1.0;
        RE[i] = (stats.expected_edges > 0) ? static_cast<double>(stats.global_edge_counts[i]) / stats.expected_edges : 1.0;
    }
    
    // ë””ë²„ê¹… ì¶œë ¥ (Rank 0ë§Œ)
    if (mpi_rank == 0) {
        printf("\n=== Label Statistics (ê¸°ì¡´ ë°©ì‹) ===\n");
        printf("Total: %d vertices, %d edges\n", stats.total_vertices, stats.total_edges);
        printf("Expected per label: %.1f vertices, %.1f edges\n", stats.expected_vertices, stats.expected_edges);
        
        for (int i = 0; i < num_partitions; i++) {
            printf("Label %d: %d vertices (%.3f), %d edges (%.3f)\n", 
                   i, stats.global_vertex_counts[i], RV[i], 
                   stats.global_edge_counts[i], RE[i]);
        }
        printf("========================\n\n");
    }

    // Penalty ì§ì ‘ ê³„ì‚°
    double rv_mean = 0.0, re_mean = 0.0;
    for (int i = 0; i < num_partitions; i++) {
        rv_mean += RV[i];
        re_mean += RE[i];
    }
    rv_mean /= num_partitions;
    re_mean /= num_partitions;

    double rv_var = 0.0, re_var = 0.0;
    for (int i = 0; i < num_partitions; i++) {
        rv_var += (RV[i] - rv_mean) * (RV[i] - rv_mean);
        re_var += (RE[i] - re_mean) * (RE[i] - re_mean);
    }
    rv_var /= num_partitions;
    re_var /= num_partitions;

    double total_var = rv_var + re_var;
    double imb_rv = (total_var > 0) ? rv_var / total_var : 0.0;
    double imb_re = (total_var > 0) ? re_var / total_var : 0.0;

    // Penalty ë°°ì—´ ì§ì ‘ ìƒì„±
    std::vector<double> penalties(num_partitions);
    for (int i = 0; i < num_partitions; i++) {
        double G_RV = (1.0 - RV[i]) / num_partitions;
        double G_RE = (1.0 - RE[i]) / num_partitions;
        penalties[i] = imb_rv * G_RV + imb_re * G_RE;
    }

    return penalties;
}
#endif

// ê²½ê³„ ë…¸ë“œë¥¼ ì°¾ëŠ” í•¨ìˆ˜ (ìµœì í™”ëœ ë²„ì „) - OpenMP ë³‘ë ¬í™”
static std::vector<int> extractBoundaryLocalIDs(const Graph &local_graph, const GhostNodes &ghost_nodes)
{
    std::vector<int> boundary_nodes;
    
    #pragma omp parallel
    {
        std::vector<int> thread_boundary_nodes;
        
        #pragma omp for nowait
        for (int u = 0; u < local_graph.num_vertices; u++) {
            int u_label = local_graph.vertex_labels[u];
            bool is_boundary = false;
            
            // uì˜ ì´ì›ƒë“¤ì„ ê²€ì‚¬
            for (int edge_idx = local_graph.row_ptr[u]; edge_idx < local_graph.row_ptr[u + 1]; edge_idx++) {
                int v = local_graph.col_indices[edge_idx];
                int v_label = getNodeLabel(v, local_graph, local_graph.vertex_labels, ghost_nodes);
                
                // ë‹¤ë¥¸ íŒŒí‹°ì…˜ ë¼ë²¨ì„ ê°€ì§„ ì´ì›ƒì´ ìˆìœ¼ë©´ ê²½ê³„ ë…¸ë“œ
                if (v_label != -1 && u_label != v_label) {
                    is_boundary = true;
                    break;
                }
            }
            
            if (is_boundary) {
                thread_boundary_nodes.push_back(u);
            }
        }
        
        #pragma omp critical
        {
            boundary_nodes.insert(boundary_nodes.end(), 
                                thread_boundary_nodes.begin(), 
                                thread_boundary_nodes.end());
        }
    }
    
    return boundary_nodes;
}

// === Edge-cut ê³„ì‚° (ìµœì í™”ëœ ë²„ì „) === - OpenMP ë³‘ë ¬í™”
static int computeEdgeCut(const Graph &g, const std::vector<int> &labels, const GhostNodes &ghost_nodes)
{
    int local_cut = 0;
    int total_edges = 0;
    
    // owned ë…¸ë“œì˜ ê°„ì„ ë§Œ ì¹´ìš´íŠ¸ (ì¤‘ë³µ ë°©ì§€) - OpenMP ë³‘ë ¬í™”
    #pragma omp parallel reduction(+:local_cut,total_edges)
    {
        #pragma omp for nowait
        for (int u = 0; u < g.num_vertices; u++) {
            for (int e = g.row_ptr[u]; e < g.row_ptr[u + 1]; e++) {
                int v = g.col_indices[e];
                total_edges++;
                
                // uì˜ ë¼ë²¨ (owned ë…¸ë“œë§Œ ì²˜ë¦¬í•˜ë¯€ë¡œ í•­ìƒ ìœ íš¨)
                int u_label = labels[u];
                
                // vì˜ ë¼ë²¨ ê²°ì • (ìµœì í™”ëœ í•¨ìˆ˜ ì‚¬ìš©)
                int v_label = getNodeLabel(v, g, labels, ghost_nodes);
                
                // ë‹¤ë¥¸ íŒŒí‹°ì…˜ ê°„ ê°„ì„ ì´ë©´ edge-cutì— í¬í•¨
                if (u_label != -1 && v_label != -1 && u_label != v_label) {
                    local_cut++;
                }
            }
        }
    }
    
    int global_cut = 0;
    int global_total_edges = 0;
    MPI_Allreduce(&local_cut, &global_cut, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);
    MPI_Allreduce(&total_edges, &global_total_edges, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);
    
    // ë¶„ì‚° í™˜ê²½ì—ì„œëŠ” ê° owned ë…¸ë“œì˜ ê°„ì„ ë§Œ ì¹´ìš´íŠ¸í•˜ë¯€ë¡œ ì¤‘ë³µì´ ì—†ìŒ
    return global_cut;
}

// === Phase2 ì‹¤í–‰ ===
PartitioningMetrics run_phase2(
    int mpi_rank, int mpi_size,
    int num_partitions,
    Graph &local_graph,
    GhostNodes &ghost_nodes,
    int gpu_id)
{
    const int max_iter = 500;
    const double epsilon = 0.03; // ìˆ˜ë ´ ê¸°ì¤€
    const int k_limit = 10;

    auto t_phase2_start = std::chrono::high_resolution_clock::now();
    
    std::cout << "[Rank " << mpi_rank << "/" << mpi_size << "] Phase2 ì‹œì‘ (GPU " << gpu_id << ")" << std::endl;
    std::cout.flush();
    
    // GPUê°€ ì´ë¯¸ í• ë‹¹ë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì„¤ì •ë§Œ í™•ì¸
    int current_device;
    cudaGetDevice(&current_device);
    if (current_device != gpu_id) {
        cudaSetDevice(gpu_id);
        std::cout << "[Rank " << mpi_rank << "] GPU " << gpu_id << " ì¬ì„¤ì • ì™„ë£Œ" << std::endl;
    }
    
    // CPU ë©”ëª¨ë¦¬ Pin ìµœì í™”: ìì£¼ ì‚¬ìš©ë˜ëŠ” ë²¡í„°ë“¤ì„ Pinned Memoryë¡œ í• ë‹¹
    std::vector<int> labels_new;
    std::vector<double> penalty_pinned;
    std::vector<int> boundary_nodes_pinned;
    
    // GPUì™€ ìì£¼ í†µì‹ í•˜ëŠ” ë©”ëª¨ë¦¬ë¥¼ Pinnedë¡œ í• ë‹¹ (ì„±ëŠ¥ í–¥ìƒ)
    labels_new.resize(local_graph.vertex_labels.size());
    penalty_pinned.reserve(num_partitions);  // ë¯¸ë¦¬ ê³µê°„ í™•ë³´
    
    // ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ë™ê¸°í™”
    MPI_Barrier(MPI_COMM_WORLD);

    // *** CRITICAL: Phase1ê³¼ Phase2 ì‚¬ì´ì˜ Ghost Node ë¼ë²¨ ë™ê¸°í™” ***
    // Phase1 ì™„ë£Œ í›„ ëª¨ë“  owned ë…¸ë“œì˜ ìµœì‹  ë¼ë²¨ì„ ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì™€ ê³µìœ 
    std::vector<Delta> all_owned_labels;
    for (int i = 0; i < local_graph.num_vertices; i++) {
        if (i < (int)local_graph.global_ids.size()) {
            Delta delta;
            delta.gid = local_graph.global_ids[i];
            delta.new_label = local_graph.vertex_labels[i];
            all_owned_labels.push_back(delta);
        }
    }
    
    // ìµœì í™”ëœ Delta í†µì‹  ì‚¬ìš©
    std::vector<Delta> recv_all_labels = allgatherDeltas(all_owned_labels, mpi_size);
    
    // Ghost ë…¸ë“œ ë¼ë²¨ ì—…ë°ì´íŠ¸
    for (const auto &delta : recv_all_labels) {
        auto it_ghost = ghost_nodes.global_to_local.find(delta.gid);
        if (it_ghost != ghost_nodes.global_to_local.end()) {
            int ghost_idx = it_ghost->second;
            if (ghost_idx >= 0 && ghost_idx < (int)ghost_nodes.ghost_labels.size()) {
                ghost_nodes.ghost_labels[ghost_idx] = delta.new_label;
                
                // local_graphì˜ vertex_labelsë„ ë™ê¸°í™”
                int ghost_lid = local_graph.num_vertices + ghost_idx;
                if (ghost_lid < (int)local_graph.vertex_labels.size()) {
                    local_graph.vertex_labels[ghost_lid] = delta.new_label;
                }
            }
        }
    }
    
    if (mpi_rank == 0) {
        std::cout << "Phase1-Phase2 ë¼ë²¨ ë™ê¸°í™” ì™„ë£Œ (ì „ì²´ ë¼ë²¨: " << recv_all_labels.size() << "ê°œ)" << std::endl;
    }

    labels_new = local_graph.vertex_labels; // í˜„ì¬ ë¼ë²¨ ë³µì‚¬ (ìµœì í™”ëœ í• ë‹¹)

    int prev_edge_cut = computeEdgeCut(local_graph, local_graph.vertex_labels, ghost_nodes);
    int convergence_count = 0;

    // ë©”ëª¨ë¦¬ í’€ ìµœì í™”: íŒŒí‹°ì…˜ í†µê³„ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì†Œí™”
    PartitionStats current_stats = computePartitionStats(local_graph, local_graph.vertex_labels, ghost_nodes, num_partitions);
    
    // ë©”ëª¨ë¦¬ ì˜ˆì•½: ë°˜ë³µì—ì„œ ì‚¬ìš©ë  ë²¡í„°ë“¤ ë¯¸ë¦¬ í• ë‹¹
    penalty_pinned.resize(num_partitions);
    std::vector<Delta> delta_changes;
    delta_changes.reserve(1000);  // ì˜ˆìƒ ë³€ê²½ì‚¬í•­ ìˆ˜ë§Œí¼ ë¯¸ë¦¬ í• ë‹¹

    for (int iter = 0; iter < max_iter; iter++) {
        // ë©”ëª¨ë¦¬ ì¬ì‚¬ìš©: labels_new ë²¡í„°ë¥¼ ì¬í• ë‹¹í•˜ì§€ ì•Šê³  ë‚´ìš©ë§Œ ë³µì‚¬
        std::copy(local_graph.vertex_labels.begin(), local_graph.vertex_labels.end(), labels_new.begin());
        
        // Step1: ìµœì í™”ëœ penalty ê³„ì‚° (í†µê³„ ì¬ì‚¬ìš©, ë©”ëª¨ë¦¬ í’€ì—ì„œ í• ë‹¹)
        penalty_pinned = calculatePenalties(current_stats, num_partitions, mpi_rank);

        // Step2: Boundary ë…¸ë“œ ì¶”ì¶œ(local id) - ë©”ëª¨ë¦¬ í’€ ì¬ì‚¬ìš©
        boundary_nodes_pinned = extractBoundaryLocalIDs(local_graph, ghost_nodes);
        
        if (boundary_nodes_pinned.empty()) {
            if (mpi_rank == 0) std::cout << "ê²½ê³„ ë…¸ë“œ ì—†ìŒ, ì¢…ë£Œ\n";
            break;
        }

        // Step3: ê³ ì„±ëŠ¥ GPU ì»¤ë„ ì‹¤í–‰ (ë‹¤ë‹¨ê³„ ìµœì í™”)
#ifdef USE_PINNED_MEMORY_OPTIMIZATION
        // 1ìˆœìœ„: Pinned Memory ìµœì í™” (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ + ìµœê³  ì„±ëŠ¥)
        try {
            runBoundaryLPOnGPU_PinnedOptimized(local_graph.row_ptr,
                                             local_graph.col_indices,
                                             local_graph.vertex_labels, // old labels
                                             labels_new,                // new labels
                                             penalty_pinned,            // pinned penalty ë°°ì—´
                                             boundary_nodes_pinned,     // pinned boundary ë°°ì—´
                                             num_partitions);
        } catch (const std::exception& e) {
            printf("[Rank %d] Pinned ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨, Thrustë¡œ ì „í™˜: %s\n", mpi_rank, e.what());
            
#ifdef USE_THRUST_OPTIMIZATION
            try {
                runBoundaryLPOnGPU_Thrust_Optimized(local_graph.row_ptr,
                                                   local_graph.col_indices,
                                                   local_graph.vertex_labels,
                                                   labels_new,
                                                   penalty_pinned,
                                                   boundary_nodes_pinned,
                                                   num_partitions);
            } catch (const std::exception& e2) {
                printf("[Rank %d] Thrust ìµœì í™”ë„ ì‹¤íŒ¨, ê¸°ë³¸ ë²„ì „ìœ¼ë¡œ ì „í™˜: %s\n", mpi_rank, e2.what());
                runBoundaryLPOnGPU_Optimized(local_graph.row_ptr,
                                           local_graph.col_indices,
                                           local_graph.vertex_labels,
                                           labels_new,
                                           penalty_pinned,
                                           boundary_nodes_pinned,
                                           num_partitions);
            }
#else
            runBoundaryLPOnGPU_Optimized(local_graph.row_ptr,
                                       local_graph.col_indices,
                                       local_graph.vertex_labels,
                                       labels_new,
                                       penalty_pinned,
                                       boundary_nodes_pinned,
                                       num_partitions);
#endif
        }
        
#elif defined(USE_THRUST_OPTIMIZATION)
        // 2ìˆœìœ„: Thrust ìµœì í™”
        try {
            runBoundaryLPOnGPU_Thrust_Optimized(local_graph.row_ptr,
                                               local_graph.col_indices,
                                               local_graph.vertex_labels, // old labels
                                               labels_new,                // new labels
                                               penalty_pinned,            // pinned penalty ë°°ì—´
                                               boundary_nodes_pinned,     // pinned boundary ë°°ì—´
                                               num_partitions);
        } catch (const std::exception& e) {
            printf("[Rank %d] Thrust ìµœì í™” ì‹¤íŒ¨, ì•ˆì „ ëª¨ë“œë¡œ ì „í™˜: %s\n", mpi_rank, e.what());
            runBoundaryLPOnGPU_Safe(local_graph.row_ptr,
                                  local_graph.col_indices,
                                  local_graph.vertex_labels,
                                  labels_new,
                                  penalty_pinned,
                                  boundary_nodes_pinned,
                                  num_partitions);
        }
#else
        // ê¸°ë³¸: í‘œì¤€ ìµœì í™”
        runBoundaryLPOnGPU_Optimized(local_graph.row_ptr,
                                   local_graph.col_indices,
                                   local_graph.vertex_labels, // old labels
                                   labels_new,                // new labels
                                   penalty_pinned,            // pinned penalty ë°°ì—´
                                   boundary_nodes_pinned,     // pinned boundary ë°°ì—´
                                   num_partitions);
#endif
        
        // GPU ë™ê¸°í™”
        cudaDeviceSynchronize();

        // Step4b: GPU ê²°ê³¼ë¥¼ ì‹¤ì œ ë¼ë²¨ ë°°ì—´ì— ì ìš© & ë³€ê²½ì‚¬í•­ì„ Deltaë¡œ ìˆ˜ì§‘
        delta_changes.clear();  // ë©”ëª¨ë¦¬ ì¬ì‚¬ìš©: clear()ë¡œ ìš©ëŸ‰ ìœ ì§€
        
        for (int lid : boundary_nodes_pinned) {
            if (lid >= 0 && lid < local_graph.num_vertices && lid < (int)labels_new.size()) {
                if (local_graph.vertex_labels[lid] != labels_new[lid]) {
                    // Delta êµ¬ì¡°ì²´ì— ë³€ê²½ì‚¬í•­ ê¸°ë¡ (ì ìš© ì „ ìƒíƒœ)
                    if (lid < (int)local_graph.global_ids.size()) {
                        Delta delta;
                        delta.gid = local_graph.global_ids[lid];
                        delta.new_label = labels_new[lid];
                        delta_changes.push_back(delta);
                    }
                    
                    // ì‹¤ì œ ë¼ë²¨ ì ìš©
                    local_graph.vertex_labels[lid] = labels_new[lid];
                }
            }
        }
        
        std::cout << "[Rank " << mpi_rank << "] Label changes: " << delta_changes.size() << std::endl;

        // Step5: ìµœì í™”ëœ Delta í†µì‹  ì‚¬ìš©
        std::vector<Delta> recv_deltas = allgatherDeltas(delta_changes, mpi_size);

        // Step5b: ìˆ˜ì‹ ëœ ë¼ë²¨ ë³€ê²½ì‚¬í•­ ì ìš©
        for (const auto &delta : recv_deltas) {
            // ghost ë…¸ë“œì¸ì§€ í™•ì¸
            auto it_ghost = ghost_nodes.global_to_local.find(delta.gid);
            if (it_ghost != ghost_nodes.global_to_local.end()) {
                int ghost_idx = it_ghost->second;
                
                // ì˜¬ë°”ë¥¸ ë²”ìœ„ í™•ì¸
                if (ghost_idx >= 0 && ghost_idx < (int)ghost_nodes.ghost_labels.size()) {
                    // Ghost ë…¸ë“œ êµ¬ì¡°ì²´ ì—…ë°ì´íŠ¸ (primary source)
                    ghost_nodes.ghost_labels[ghost_idx] = delta.new_label;
                    
                    // local_graphì˜ vertex_labelsë„ ë™ê¸°í™” (ghost ë…¸ë“œ ë¶€ë¶„)
                    int ghost_lid = local_graph.num_vertices + ghost_idx;
                    if (ghost_lid < (int)local_graph.vertex_labels.size()) {
                        local_graph.vertex_labels[ghost_lid] = delta.new_label;
                    }
                }
            }
        }

        // Step6: Edge-cut ë³€í™”ìœ¨ ê²€ì‚¬
        int curr_edge_cut = computeEdgeCut(local_graph, local_graph.vertex_labels, ghost_nodes);
        double delta = (prev_edge_cut > 0)
                           ? std::abs((double)(curr_edge_cut - prev_edge_cut) / prev_edge_cut)
                           : 1.0;
        
        // ìˆ˜ë ´ ì¡°ê±´ í™•ì¸ (edge-cut ë³€í™”ìœ¨ì´ epsilon ë¯¸ë§Œì¼ ë•Œ)
        if (delta < epsilon) {
            convergence_count++;
        } else {
            convergence_count = 0; // ë¦¬ì…‹
        }
        
        // ë°˜ë³µ ê²°ê³¼ ì¶œë ¥
        if (mpi_rank == 0) {
            std::cout << "Iter " << iter + 1 << ": Edge-cut " << curr_edge_cut 
                      << " (delta: " << std::fixed << std::setprecision(3) << delta * 100 << "%)";
            
            if (convergence_count > 0) {
                std::cout << " [ìˆ˜ë ´ ì¹´ìš´íŠ¸: " << convergence_count << "/" << k_limit << "]";
            }
            std::cout << "\n";
        }
        prev_edge_cut = curr_edge_cut;
        
        // ìˆ˜ë ´ ì™„ë£Œ ì¡°ê±´: edge-cut ë³€í™”ìœ¨ì´ epsilon ë¯¸ë§Œìœ¼ë¡œ k_limit ë²ˆ ì—°ì† ë°œìƒ
        if (convergence_count >= k_limit) {
            if (mpi_rank == 0) {
                std::cout << "ìˆ˜ë ´ ì™„ë£Œ! (ì—°ì† " << k_limit << "íšŒ ë³€í™”ìœ¨ < " 
                          << std::fixed << std::setprecision(1) << epsilon * 100 << "%)\n";
            }
            break;
        }
        
        // ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•´ íŒŒí‹°ì…˜ í†µê³„ ì—…ë°ì´íŠ¸ (ë¼ë²¨ì´ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ)
        if (!delta_changes.empty() || !recv_deltas.empty()) {
            current_stats = computePartitionStats(local_graph, local_graph.vertex_labels, ghost_nodes, num_partitions);
        }
    }

    auto t_phase2_end = std::chrono::high_resolution_clock::now();
    long exec_ms = std::chrono::duration_cast<std::chrono::milliseconds>(t_phase2_end - t_phase2_start).count();

    // GPU ì‚¬ìš© í†µê³„ ì¶œë ¥
    std::cout << "[Rank " << mpi_rank << "] Phase2 ì™„ë£Œ - GPU " << gpu_id 
              << " ì´ ì‹¤í–‰ì‹œê°„: " << exec_ms << "ms" << std::endl;
    
    // ìµœì¢… Balance ê³„ì‚°ì„ ìœ„í•œ í†µê³„ (ì´ë¯¸ ê³„ì‚°ëœ current_stats ì¬ì‚¬ìš©)
    PartitionStats final_stats = computePartitionStats(local_graph, local_graph.vertex_labels, ghost_nodes, num_partitions);

    double max_vertex_ratio = 0.0, max_edge_ratio = 0.0;
    double sum_vertex_ratio = 0.0, sum_edge_ratio = 0.0;
    
    for (int i = 0; i < num_partitions; i++) {
        double rv = (final_stats.expected_vertices > 0) ? static_cast<double>(final_stats.global_vertex_counts[i]) / final_stats.expected_vertices : 1.0;
        double re = (final_stats.expected_edges > 0) ? static_cast<double>(final_stats.global_edge_counts[i]) / final_stats.expected_edges : 1.0;
        
        max_vertex_ratio = std::max(max_vertex_ratio, rv);
        max_edge_ratio = std::max(max_edge_ratio, re);
        sum_vertex_ratio += rv;
        sum_edge_ratio += re;
    }
    
    double avg_vertex_ratio = sum_vertex_ratio / num_partitions;
    double avg_edge_ratio = sum_edge_ratio / num_partitions;

    PartitioningMetrics m2;
    m2.edge_cut = prev_edge_cut;
    m2.vertex_balance = max_vertex_ratio / avg_vertex_ratio;
    m2.edge_balance = max_edge_ratio / avg_edge_ratio;
    m2.loading_time_ms = exec_ms;
    m2.distribution_time_ms = 0;
    m2.num_partitions = num_partitions;
    
    // ì´ë¯¸ ê³„ì‚°ëœ í†µê³„ì—ì„œ ì „ì—­ ì •ë³´ ì‚¬ìš©
    m2.total_vertices = final_stats.total_vertices;
    m2.total_edges = final_stats.total_edges;

    MPI_Barrier(MPI_COMM_WORLD);
    cudaDeviceSynchronize();  // ëª¨ë“  GPU ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    std::cout << "[Rank " << mpi_rank << "] GPU " << gpu_id << " ì‘ì—… ì™„ë£Œ" << std::endl;
    std::cout.flush();
    
    return m2;
}