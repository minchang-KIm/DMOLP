# DMOLP ê¸°ëŠ¥ ëª…ì„¸ì„œ
## Distributed Multi-Objective Label Propagation System

**ì‘ì„±ì¼**: 2025ë…„ 7ì›” 22ì¼  
**ë²„ì „**: 2.0  
**ì‘ì„±ì**: ê¹€ë¯¼ì°½  

---

## ğŸ“‹ 1. ì‹œìŠ¤í…œ ê°œìš”

### 1.1 í”„ë¡œì íŠ¸ ëª©ì 
DMOLPëŠ” ëŒ€ê·œëª¨ ê·¸ë˜í”„ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„í• í•˜ê¸° ìœ„í•œ **ë¶„ì‚° ë¼ë²¨ ì „íŒŒ ê¸°ë°˜ ê·¸ë˜í”„ íŒŒí‹°ì…”ë‹ ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤. MPI ë¶„ì‚° í™˜ê²½ê³¼ CUDA GPU ê°€ì†ì„ í†µí•´ ìˆ˜ì–µ ê°œì˜ ì •ì ê³¼ ê°„ì„ ì„ ê°€ì§„ ëŒ€ê·œëª¨ ê·¸ë˜í”„ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1.2 ì£¼ìš” íŠ¹ì§•
- **2ë‹¨ê³„ ì•Œê³ ë¦¬ì¦˜**: Phase 1(ì´ˆê¸° ë¶„í• ) + Phase 2(ë™ì  ìµœì í™”)
- **í•˜ì´ë¸Œë¦¬ë“œ ë³‘ë ¬ì²˜ë¦¬**: MPI(ë…¸ë“œ ê°„) + OpenMP(ë…¸ë“œ ë‚´) + CUDA(GPU ê°€ì†)
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: CSR ê·¸ë˜í”„ í‘œí˜„ + ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
- **í™•ì¥ì„±**: ìˆ˜í‰ì  í™•ì¥(ë…¸ë“œ ì¶”ê°€) + ìˆ˜ì§ì  í™•ì¥(GPU í™œìš©)

### 1.3 ì„±ëŠ¥ ì§€í‘œ
- **Edge-cut ê°ì†Œìœ¨**: 94%+ (ê¸°ì¡´ í•´ì‹œ ë¶„í•  ëŒ€ë¹„)
- **ì²˜ë¦¬ ì†ë„**: 1ì–µ ê°„ì„  ê·¸ë˜í”„ 3-4ì´ˆ ë‚´ ì²˜ë¦¬
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  80%+
- **í™•ì¥ì„±**: ì„ í˜• í™•ì¥ (ë…¸ë“œ ìˆ˜ì— ë¹„ë¡€í•œ ì„±ëŠ¥ í–¥ìƒ)

---

## ğŸ—ï¸ 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2.1 ëª¨ë“ˆ êµ¬ì¡°
```
DMOLP/
â”œâ”€â”€ ğŸ“ include/           # í—¤ë” íŒŒì¼
â”‚   â”œâ”€â”€ types.h          # ë°ì´í„° êµ¬ì¡°ì²´ ì •ì˜
â”‚   â”œâ”€â”€ phase1.h         # Phase 1 ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ mpi_workflow.h   # MPI ë¶„ì‚° ì²˜ë¦¬
â”‚   â””â”€â”€ cuda_kernels.h   # CUDA GPU ì»¤ë„
â”œâ”€â”€ ğŸ“ src/             # êµ¬í˜„ íŒŒì¼
â”‚   â”œâ”€â”€ main.cpp        # CPU ë©”ì¸ ì§„ì…ì 
â”‚   â”œâ”€â”€ main_clean.cu   # CUDA ë©”ì¸ ì§„ì…ì 
â”‚   â”œâ”€â”€ phase1_clean.cpp # ê·¸ë˜í”„ ë¡œë”© ë° ì´ˆê¸° ë¶„í• 
â”‚   â”œâ”€â”€ mpi_workflow.cpp # MPI í†µì‹  ì›Œí¬í”Œë¡œìš°
â”‚   â”œâ”€â”€ cuda_kernels.cu  # GPU ì»¤ë„ êµ¬í˜„
â”‚   â”œâ”€â”€ convergence_ghost.cpp # ê³ ìŠ¤íŠ¸ ë…¸ë“œ ìˆ˜ë ´ ì•Œê³ ë¦¬ì¦˜
â”‚   â”œâ”€â”€ label_propagation.cpp # ë¼ë²¨ ì „íŒŒ ë¡œì§
â”‚   â”œâ”€â”€ algorithm_steps.cpp   # 7ë‹¨ê³„ ì•Œê³ ë¦¬ì¦˜
â”‚   â””â”€â”€ results.cpp     # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
â””â”€â”€ ğŸ“ build_scripts/   # ë¹Œë“œ ìë™í™”
    â”œâ”€â”€ build_cpu.sh    # CPU ë²„ì „ ë¹Œë“œ
    â””â”€â”€ build_gpu.sh    # GPU ë²„ì „ ë¹Œë“œ
```

### 2.2 ë°ì´í„° í”Œë¡œìš°
```
[ê·¸ë˜í”„ íŒŒì¼] 
    â†“ Phase 1
[ì´ˆê¸° í•´ì‹œ ë¶„í• ]
    â†“ MPI ë¶„ì‚°
[ë…¸ë“œë³„ ë¶€ë¶„ ê·¸ë˜í”„]
    â†“ Phase 2 (7ë‹¨ê³„ ë°˜ë³µ)
[ë™ì  ë¼ë²¨ ì „íŒŒ]
    â†“ GPU ê°€ì†
[ìµœì í™”ëœ íŒŒí‹°ì…˜]
    â†“ ê²°ê³¼ ìˆ˜ì§‘
[Edge-cut ìµœì†Œí™” ì™„ë£Œ]
```

---

## âš™ï¸ 3. ê¸°ëŠ¥ ëª…ì„¸

### 3.1 Phase 1: ê·¸ë˜í”„ ë¡œë”© ë° ì´ˆê¸° ë¶„í• 

#### 3.1.1 ê·¸ë˜í”„ íŒŒì¼ íŒŒì‹±
```cpp
// ì§€ì› í˜•ì‹
- METIS í˜•ì‹ (.graph, .mtx)
- Adjacency List í˜•ì‹ (.adj)
- ì´ì§„ ê·¸ë˜í”„ í˜•ì‹ (.bin)

// ì£¼ìš” ê¸°ëŠ¥
- ë©€í‹°ìŠ¤ë ˆë“œ íŒŒì¼ I/O
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ìŠ¤íŠ¸ë¦¬ë° ë¡œë“œ
- CSR (Compressed Sparse Row) ë³€í™˜
```

#### 3.1.2 ì´ˆê¸° ë¶„í•  ì•Œê³ ë¦¬ì¦˜
```cpp
// í•´ì‹œ ê¸°ë°˜ ì •ì  ë¶„í• 
partition_id = vertex_id % num_partitions

// íŠ¹ì§•:
- O(1) ì‹œê°„ ë³µì¡ë„
- ê· ë“±í•œ ì •ì  ë¶„ì‚°
- MPI ë…¸ë“œ ê°„ ë¶€í•˜ ë¶„ì‚°
```

### 3.2 Phase 2: 7ë‹¨ê³„ ë™ì  ë¼ë²¨ ì „íŒŒ

#### 3.2.1 Step 1: RV/RE ê³„ì‚°
**ëª©ì **: ê° íŒŒí‹°ì…˜ì˜ ì •ì /ê°„ì„  ë¹„ìœ¨ ê³„ì‚°
```cpp
struct PartitionStats {
    int vertex_count;      // ì •ì  ìˆ˜
    int edge_count;        // ê°„ì„  ìˆ˜  
    double rv_ratio;       // ì •ì  ë¹„ìœ¨ (target: 1/k)
    double re_ratio;       // ê°„ì„  ë¹„ìœ¨ (target: 1/k)
};
```

#### 3.2.2 Step 2: ë¶ˆê· í˜• ê³„ì‚°
**ëª©ì **: íŒŒí‹°ì…˜ ê°„ ë¶ˆê· í˜• ì •ë„ ì¸¡ì •
```cpp
// Vertex Balance
double vertex_balance = max(partition_vertices) / avg(partition_vertices)

// Edge Balance  
double edge_balance = max(partition_edges) / avg(partition_edges)

// ëª©í‘œ: 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê· í˜•ì¡íŒ ë¶„í• 
```

#### 3.2.3 Step 3: Edge-cut ê³„ì‚°
**ëª©ì **: íŒŒí‹°ì…˜ ê²½ê³„ì˜ ê°„ì„  ìˆ˜ ê³„ì‚° (ìµœì†Œí™” ëª©í‘œ)
```cpp
// GPU ê°€ì† ë³‘ë ¬ ê³„ì‚°
__global__ void calculateEdgeCutKernel(
    const int* vertex_labels,    // ì •ì  ë¼ë²¨
    const int* row_ptr,         // CSR í–‰ í¬ì¸í„°
    const int* col_indices,     // CSR ì—´ ì¸ë±ìŠ¤
    int* edge_cut,              // ê²°ê³¼ ì €ì¥
    int num_vertices            // ì •ì  ìˆ˜
) {
    int vertex = blockIdx.x * blockDim.x + threadIdx.x;
    if (vertex >= num_vertices) return;
    
    int vertex_label = vertex_labels[vertex];
    int local_edge_cut = 0;
    
    // ì´ì›ƒ ì •ì ë“¤ ê²€ì‚¬
    for (int edge_idx = row_ptr[vertex]; edge_idx < row_ptr[vertex + 1]; ++edge_idx) {
        int neighbor = col_indices[edge_idx];
        if (neighbor < num_vertices && vertex < neighbor) {
            int neighbor_label = vertex_labels[neighbor];
            if (vertex_label != neighbor_label) {
                local_edge_cut++;  // ê²½ê³„ ê°„ì„  ë°œê²¬
            }
        }
    }
    
    if (local_edge_cut > 0) {
        atomicAdd(edge_cut, local_edge_cut);  // ì›ìì  ëˆ„ì 
    }
}
```

#### 3.2.4 Step 4: ë™ì  ë¼ë²¨ ì „íŒŒ (í•µì‹¬ ì•Œê³ ë¦¬ì¦˜)
**ëª©ì **: ê²½ê³„ ì •ì ë“¤ì˜ ë¼ë²¨ì„ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ Edge-cut ìµœì†Œí™”

```cpp
// GPU ì»¤ë„ - ëŒ€ê·œëª¨ ë³‘ë ¬ ì²˜ë¦¬
__global__ void dynamicLabelPropagationKernelUnified(
    int* vertex_labels,           // ì •ì  ë¼ë²¨ (ì…ì¶œë ¥)
    const int* row_ptr,          // CSR í–‰ í¬ì¸í„°
    const int* col_indices,      // CSR ì—´ ì¸ë±ìŠ¤  
    const int* boundary_vertices, // ê²½ê³„ ì •ì  ë¦¬ìŠ¤íŠ¸
    int* label_changes,          // ë³€ê²½ íšŸìˆ˜ ì¹´ìš´í„°
    int* update_flags,           // ì—…ë°ì´íŠ¸ í”Œë˜ê·¸
    int num_boundary_vertices,   // ê²½ê³„ ì •ì  ìˆ˜
    int num_partitions,          // íŒŒí‹°ì…˜ ìˆ˜
    int mpi_rank,               // MPI ë­í¬
    int num_vertices,           // ì „ì²´ ì •ì  ìˆ˜
    int start_vertex,           // ì‹œì‘ ì •ì 
    int end_vertex              // ë ì •ì 
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    if (tid >= num_boundary_vertices) return;
    
    int vertex = boundary_vertices[tid];
    if (vertex < start_vertex || vertex >= end_vertex) return;
    
    int current_label = vertex_labels[vertex];
    int best_label = current_label;
    double best_score = 0.0;
    
    // ì´ì›ƒ ì •ì ë“¤ì˜ ë¼ë²¨ ë¶„ì„
    for (int edge_idx = row_ptr[vertex]; edge_idx < row_ptr[vertex + 1]; ++edge_idx) {
        int neighbor = col_indices[edge_idx];
        int neighbor_label = vertex_labels[neighbor];
        
        if (neighbor_label != current_label && neighbor_label < num_partitions) {
            // ìŠ¤ì½”ì–´ ê³„ì‚° (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
            double score = 1.0;
            if (score > best_score) {
                best_score = score;
                best_label = neighbor_label;
            }
        }
    }
    
    // ë¼ë²¨ ì—…ë°ì´íŠ¸
    if (best_label != current_label) {
        vertex_labels[vertex] = best_label;
        atomicAdd(label_changes, 1);  // ë³€ê²½ íšŸìˆ˜ ì¦ê°€
    }
}
```

#### 3.2.5 Step 5: íŒŒí‹°ì…˜ ì—…ë°ì´íŠ¸ êµí™˜ (MPI í†µì‹ )
**ëª©ì **: ë…¸ë“œ ê°„ ë¼ë²¨ ë³€ê²½ ì‚¬í•­ ë™ê¸°í™”

```cpp
void MPIDistributedWorkflowV2::exchangePartitionUpdates() {
    // 1. ë¡œì»¬ ì—…ë°ì´íŠ¸ ìˆ˜ì§‘
    std::vector<int> local_updates = collectLocalUpdates();
    
    // 2. MPI Allgathervë¡œ ëª¨ë“  ë…¸ë“œì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
    int send_count = local_updates.size();
    std::vector<int> recv_counts(mpi_size_);
    MPI_Allgather(&send_count, 1, MPI_INT, recv_counts.data(), 1, MPI_INT, MPI_COMM_WORLD);
    
    // 3. ì „ì²´ ì—…ë°ì´íŠ¸ ìˆ˜ì‹ 
    std::vector<int> all_updates = gatherAllUpdates(local_updates, recv_counts);
    
    // 4. ê³ ìŠ¤íŠ¸ ë…¸ë“œ ì—…ë°ì´íŠ¸ ì ìš©
    applyGhostNodeUpdates(all_updates);
}
```

#### 3.2.6 Step 6: ìˆ˜ë ´ í™•ì¸
**ëª©ì **: ì•Œê³ ë¦¬ì¦˜ ì¢…ë£Œ ì¡°ê±´ ê²€ì‚¬

```cpp
struct ConvergenceMetrics {
    double edge_cut_improvement;    // Edge-cut ê°œì„ ë¥ 
    int total_label_changes;       // ì´ ë¼ë²¨ ë³€ê²½ ìˆ˜
    double balance_improvement;     // ê· í˜•ë„ ê°œì„ ë¥ 
    int iteration_count;           // ë°˜ë³µ íšŸìˆ˜
    
    bool isConverged() const {
        return (edge_cut_improvement < 0.01) ||  // 1% ë¯¸ë§Œ ê°œì„ 
               (total_label_changes < num_vertices * 0.001) ||  // 0.1% ë¯¸ë§Œ ë³€ê²½
               (iteration_count >= MAX_ITERATIONS);  // ìµœëŒ€ ë°˜ë³µ ë„ë‹¬
    }
};
```

#### 3.2.7 Step 7: ë‹¤ìŒ ë°˜ë³µ ì¤€ë¹„
**ëª©ì **: ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ë‹¤ìŒ ë¼ìš´ë“œ ì¤€ë¹„

```cpp
void prepareNextIteration() {
    // 1. ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    updateMetricsHistory();
    
    // 2. ê²½ê³„ ì •ì  ë¦¬ìŠ¤íŠ¸ ê°±ì‹ 
    updateBoundaryVertices();
    
    // 3. GPU ë©”ëª¨ë¦¬ ë™ê¸°í™”
    gpu_manager_->synchronize();
    
    // 4. MPI ë™ê¸°í™” í¬ì¸íŠ¸
    MPI_Barrier(MPI_COMM_WORLD);
}
```

---

## ğŸ“Š 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­

### 4.1 ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ

#### 4.1.1 Edge-cut (í•µì‹¬ ì§€í‘œ)
- **ì •ì˜**: ì„œë¡œ ë‹¤ë¥¸ íŒŒí‹°ì…˜ì— ì†í•œ ì •ì  ê°„ ê°„ì„  ìˆ˜
- **ëª©í‘œ**: ìµœì†Œí™” (í†µì‹  ë¹„ìš© ê°ì†Œ)
- **ì¸¡ì •**: GPU ë³‘ë ¬ ê³„ì‚°ìœ¼ë¡œ O(E) ì‹œê°„

#### 4.1.2 Load Balance
```cpp
// Vertex Balance
double vb = max_vertices / avg_vertices;  // ëª©í‘œ: 1.0

// Edge Balance  
double eb = max_edges / avg_edges;        // ëª©í‘œ: 1.0
```

#### 4.1.3 ì‹¤í–‰ ì‹œê°„ ë¶„ì„
```
Phase 1 (ê·¸ë˜í”„ ë¡œë”©): ~10% 
Phase 2 ë°˜ë³µ:
  - Step 1-2 (ë©”íŠ¸ë¦­ ê³„ì‚°): ~5%
  - Step 3 (Edge-cut): ~15% 
  - Step 4 (ë¼ë²¨ ì „íŒŒ): ~60%    â† GPU ì§‘ì¤‘
  - Step 5 (MPI í†µì‹ ): ~15%
  - Step 6-7 (ìˆ˜ë ´ í™•ì¸): ~5%
```

### 4.2 ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

#### 4.2.1 GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
```cpp
class GPUMemoryManager {
private:
    // ì—°ì† ë©”ëª¨ë¦¬ í• ë‹¹ìœ¼ë¡œ ìºì‹œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
    int* d_vertex_labels_;     // ì •ì  ë¼ë²¨
    int* d_row_ptr_;          // CSR í–‰ í¬ì¸í„°
    int* d_col_indices_;      // CSR ì—´ ì¸ë±ìŠ¤
    int* d_boundary_vertices_; // ê²½ê³„ ì •ì 
    
    // ì›ìì  ì—°ì‚°ìš© ì¹´ìš´í„°
    int* d_label_changes_;    // ë¼ë²¨ ë³€ê²½ íšŸìˆ˜
    int* d_edge_cut_;         // Edge-cut ê°’
    
public:
    // ìŠ¤íŠ¸ë¦¬ë° ë©”ëª¨ë¦¬ ì „ì†¡
    void copyToGPUAsync(const std::vector<int>& data, cudaStream_t stream);
    
    // ë©”ëª¨ë¦¬ í’€ë§ìœ¼ë¡œ í• ë‹¹/í•´ì œ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
    void preallocateMemoryPool(size_t pool_size);
};
```

#### 4.2.2 CUDA ì»¤ë„ ìµœì í™”
```cpp
// ë¸”ë¡ í¬ê¸°: Tesla V100 ìµœì í™”
constexpr int BLOCK_SIZE = 256;

// ê·¸ë¦¬ë“œ í¬ê¸°: GPU ì ìœ ìœ¨ ê·¹ëŒ€í™”
int grid_size = (num_elements + BLOCK_SIZE - 1) / BLOCK_SIZE;

// ê³µìœ  ë©”ëª¨ë¦¬ í™œìš© (í–¥í›„ í™•ì¥)
__shared__ int shared_labels[BLOCK_SIZE];

// ë©”ëª¨ë¦¬ ì ‘í•© íŒ¨í„´ ìµœì í™”
// - ì—°ì†ì  ë©”ëª¨ë¦¬ ì ‘ê·¼
// - ë±…í¬ ì¶©ëŒ ë°©ì§€
```

---

## ğŸ”§ 5. ë¹Œë“œ ë° ë°°í¬

### 5.1 ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

#### 5.1.1 í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
```
CPU: x86_64, ìµœì†Œ 4ì½”ì–´ (ê¶Œì¥: 16ì½”ì–´+)
RAM: ìµœì†Œ 8GB (ê¶Œì¥: 32GB+)
GPU: NVIDIA Tesla V100/A100 (ê¶Œì¥)
Network: InfiniBand (ë‹¤ì¤‘ ë…¸ë“œ í™˜ê²½)
```

#### 5.1.2 ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­
```
OS: Ubuntu 20.04 LTS / CentOS 8+
Compiler: GCC 9.0+ / Clang 10.0+
CUDA: 11.0+ (GPU ë²„ì „)
MPI: OpenMPI 4.0+ / MPICH 3.3+
CMake: 3.18+
```

### 5.2 ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸

#### 5.2.1 CPU ë²„ì „ ë¹Œë“œ
```bash
# ìë™ ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
./build_cpu.sh

# ìˆ˜ë™ ë¹Œë“œ
mkdir build_cpu && cd build_cpu
cmake .. -DUSE_CUDA=OFF -DCMAKE_BUILD_TYPE=Release
make -j$(nproc)
```

#### 5.2.2 GPU ë²„ì „ ë¹Œë“œ  
```bash
# ìë™ ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
./build_gpu.sh

# ìˆ˜ë™ ë¹Œë“œ
mkdir build_gpu && cd build_gpu  
cmake .. -DUSE_CUDA=ON -DCMAKE_BUILD_TYPE=Release
make -j$(nproc)
```

### 5.3 ì‹¤í–‰ ë°©ë²•

#### 5.3.1 ë‹¨ì¼ ë…¸ë“œ ì‹¤í–‰
```bash
# CPU ë²„ì „
mpirun -np 4 ./dmolp graph.mtx 8

# GPU ë²„ì „ (GPUë³„ í”„ë¡œì„¸ìŠ¤)
mpirun -np 2 ./dmolp graph.mtx 8
```

#### 5.3.2 ë‹¤ì¤‘ ë…¸ë“œ ì‹¤í–‰
```bash
# MPI í˜¸ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
echo "node1 slots=8" > hostfile
echo "node2 slots=8" >> hostfile

# ë¶„ì‚° ì‹¤í–‰
mpirun -np 16 -hostfile hostfile ./dmolp large_graph.mtx 16
```

---

## ğŸ“ˆ 6. í™•ì¥ì„± ë° í–¥í›„ ë°œì „ ë°©í–¥

### 6.1 ìŠ¤ì¼€ì¼ë§ íŠ¹ì„±
- **ìˆ˜í‰ì  í™•ì¥**: MPI ë…¸ë“œ ì¶”ê°€ë¡œ ì„ í˜• ì„±ëŠ¥ í–¥ìƒ
- **ìˆ˜ì§ì  í™•ì¥**: GPU ë©”ëª¨ë¦¬ í¬ê¸°ì— ë”°ë¥¸ ì²˜ë¦¬ ëŠ¥ë ¥ ì¦ëŒ€
- **ë©”ëª¨ë¦¬ í™•ì¥**: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì œì•½ ê·¹ë³µ

### 6.2 í–¥í›„ ê°œì„  ì‚¬í•­
1. **ë‹¤ì¤‘ GPU ì§€ì›**: ë…¸ë“œë‹¹ ì—¬ëŸ¬ GPU í™œìš©
2. **ë™ì  ë¡œë“œ ë°¸ëŸ°ì‹±**: ì‹¤í–‰ ì¤‘ ì‘ì—… ì¬ë¶„ë°°  
3. **ì••ì¶• ì•Œê³ ë¦¬ì¦˜**: ê·¸ë˜í”„ ë°ì´í„° ì••ì¶•ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
4. **ìŠ¤ë§ˆíŠ¸ ìŠ¤ì¼€ì¤„ë§**: GPU/CPU í•˜ì´ë¸Œë¦¬ë“œ ì‘ì—… ìŠ¤ì¼€ì¤„ë§

---

**ë¬¸ì„œ ë²„ì „**: 2.0  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025ë…„ 7ì›” 22ì¼  
**ë‹¤ìŒ ë¦¬ë·°**: 2025ë…„ 8ì›” 22ì¼
